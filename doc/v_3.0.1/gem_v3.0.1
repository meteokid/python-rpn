
        ############# GEMDM Model -- Version 3.0.1 ###############
                              July 25 2002

        Version 3.0.1 of the GEMDM dynamics is now ready and available 
        in directory:
              "$ARMNLIB/modeles/GEMDM_shared/v_3.0.1/RCS_DYN"
	It is connected to RPN/CMC physics version 3.72 in directory:
	      "$ARMNLIB/modeles/PHY/v_3.72/RCS:3.72"
        for which 2 patches have been released: ky and gwd2

#################### IMPORTANT NOTES ########################

A) This version contains minor updates for all global configurations 
   and contains major updates (specially in the entry program) 
   allowing for the first time to test LAM configurations.

B) This version will NOT bit-pattern validate against version 2.3.2.

C) The tested configurations are listed in $gem/scripts/lacommande

D) Reference informations on how to run the model interactively or
   in batch mode can be found at the end of this release note
   in section GEMDM ENVIRONMENT. This release note along with all 
   previous ones can be found in ~armnmod/revi_modeles. 

#############################################################

MAIN FEATURES:

1) Beta version of the LAM configuration;
    The whole dynamics has been adapted to run on a Limited Area
    domain (LAM) using lateral boundary specifications from Thomas
    et. al (1998) for the semi-Lagrangian transport and elliptic
    problem. The LAM pressure solver is an adaptation of the
    solver for global grids described in Qaddouri et al. (2000).
    The horizontal sponge zone (blending zone) has been taken
    directly from MC2 v_4.9.3 and is essentially the work of
    Robert and Yakimiw (1986).

    On a very specific LAM grid, a 6 timesteps acid-test which 
    excludes horizontal diffusion, physics, vertical sponge and 
    filtering of the topography has been realized with results 
    matching the global (driving) solution with machine precision. 
    Version 3.0.1 will now be used in the coming months to test more 
    realistic LAM configurations.

2) A major reshaping of the entry program has been achieved
   to simplify the code and ease the implementation of the LAM 
   configuration. This includes the introduction of a new
   way to define computational grids along with a new horizontal 
   interpolation package. All previous grid parameters from
   namelist &grid have been eliminated or have changed name.
   The following is now being used (from gem_settings.doc):
*____________________________________________________________________|
*           |                                                 |      |
* NAME      | DESCRIPTION                                     |DEFVAL|
*-----------|-------------------------------------------------|------|
* Grd_typ_S | Computational grid type: first letter is G or L | "GU" |
*           | for Global or Lam, second letter is U or V      |      |
*           | for Uniform or Variable mesh                    |      |
* Grd_ni    | number of points in x                           |  0   |
* Grd_nj    | number of points in y                           |  0   |
* Grd_lon1  | geographic longitude of the center of the       |  0.0 |
*           | computational domain when roule= .true.         |      |
* Grd_lat1  | geographic latitude of the center of the        |  0.0 |
*           | computational domain when roule= .true.         |      |
* Grd_lon2  | geographic longitude of a point on the equator  |  0.0 |
*           | of the computational domain when roule= .true.  |      |
* Grd_lat2  | geographic latitude of a point on the equator of|  0.0 |
*           | the computational domain when roule= .true.     |      |
* Grd_roule | .TRUE. for rotated coordinate system            |false |
*           |                                                 |      |
*           |                                                 |      |
* The following 2 parameters apply only for uniform portion   |      |
*               of GV grids and for LU grids                  |      |
* Grd_dx    | mesh length (resolution) in x-direction(degrees)|  0.  |
* Grd_dy    | mesh length (resolution) in y-direction(degrees)|  0.  |
*           |                                                 |      |
* The following 4 parameters apply only for GV grids          |      |
* Grd_nila  | number of points in x of the uniform resolution |  0   |
*           |                                          domain |      |
* Grd_njla  | number of points in y of the uniform resolution |  0   |
*           |                                          domain |      |
* Grd_dxmax | maximum grid point spacing along x (degrees)    | 360. |
* Grd_dymax | maximum grid point spacing along y (degrees)    | 180. |
*           |                                                 |      |
The following 4 parameters apply only for LAM grids           |      |
* Grd_iref  | I reference point (within  Grd_ni)              | 1    |
* Grd_jref  | J reference point (within  Grd_nj)              | 1    |
* Grd_latr  | latitude  of reference point                    | 0.   |
*           | (Grd_iref,Grd_jref) on rotated grid             | 0.   |
* Grd_lonr  | longitude of reference point                    | 0.   |
*           | (Grd_iref,Grd_jref) on rotated grid             |      |
*____________________________________________________________________|

3) A major machine optimization has been added to the elliptic
   problem solution on global grids. Eigenmodes with definite
   parity significantly accelerates the pressure solver and the HO
   horizontal diffusion. &gem_cfgs namelist variable 'Eigv_parity_L'  
   (default=.false.) is used to activate this feature.

4) Vertical coordinate (namelist variable "hyb" from &gem_cfgs):

   In the previous versions with the hybrid eta levels, the user could
   only specify a normalized hybrid (NHyb) list which would then be
   internally converted to a non-normalized (Hyb) list with the
   relation Hyb = NHyb + (1-NHyb) * Pres_ptop / P_00. The default
   for Pres_ptop was 10. (mb) and P_00 is hardcoded to 800. (mb).

   The new default for Pres_ptop is now -1.0 (meaning unspecified)
   and the user is allowed to directly specify a non-normalized 
   (Hyb) list. This list must be given in a monotonically increasing
   order ending with hyb(nk) = 1.0. In that manner Pres_ptop will
   be deduced from the relation above.

   If however the user chooses to specify Pres_ptop in the &gem_cfgs
   namelist (any value > 0.), then he can only specify a normalized 
   hybrid (NHyb) list with the same restrictions as before.

   On output, the "hyb" list will be encoded in ip1 using:

     - only newstyle encoding for non-normalized (Hyb) list thus
       the user can only ask for FST98 files for output
     - user choice (newstyle or oldstyle) determined through &gem_cfgs
       namelist variable Level_ip12000_L (delault=.false.) when a 
       normalized (NHyb) list is given

5) Synchronization with V4D routines + linear physics

6) New option to diffuse real wind instead of wind images within
   the vertical sponge scheme. Namelist variable Vspng_rwnd_L
   from &gem_cfgs namelist (default=.false.) is used to control
   this option.

7) New horizontal sponge (similar to vertical sponge) to control
   problems near the numerical poles. The following namelist
   variables from &gem_cfgs are used to control that scheme:
*____________________________________________________________________|
*           |                                                 |      |
* NAME      | DESCRIPTION                                     |DEFVAL|
*-----------|-------------------------------------------------|------|
* Hspng_nj  | Number of rows from numerical poles on which    |  0   |
*           | to apply an increasing FACT horizontal diffusion|      |
* Hspng_mf  | Multiplicative factor(s) of horizontal          | 800  |
*           | diffusion coefficient                           |      |
* Hspng_uvwdt_L | Logical control to limit application of     | true |
*           | horizontal sponge on momentum variables only    |      |
* Hspng_rwnd_L | Logical control to diffuse real wind instead | false|
*           | of wind images within the hor. sponge scheme    |      |

8) Miscelleneous and bugfixes:

  - bugfix in the computation of vertical motion for the physics
    package (subroutine p_vmmphy.ftn)
  - only PE #0 now writes $CMCLOG logfile
  - on output, longitudes are now strictly positive definite
  - new defaults (&gem_cfgs namelist):
	Pres_ptop      = -1.
	Hzd_uvwdt_L    = .true.
	Vspng_uvwdt_L  = .true.
  - output of TW now possible
  - port to Linux now complete
  - &gement namelist variables pack, pilot, debug and Topo_mtdf
     have been eliminated (not used)
  - &gement namelist variable etik has changed to Out1_etik_s
  - &gem_cfgs namelist variable Geomd_rcoef has changed to Grd_rcoef

Ref:

Robert, A. and E. Yakimiw, 1986: Identification and elimination of an
   inflow boundary computational solution in limited area model
   integrations. Atmos.-Ocean, 24, 369-385

Thomas Steve, Claude Girard, Robert Benoit, Michel Desgagne 
   and Pierre pellerin, 1998: A New Adiabatic Kernel for the MC2 Model. 
   Atmos.-Ocean, 36, 241-270

Qaddouri, A., J. Cote and M. Valin, 2000: A parallel direct 3D solver.
  In "High performance computing systems and applications" A. Pollard,
  D. J. K. Mewhort, D. F. Weaver (ed.). Kluwer Academic Publishers, 429-442.
   
  
#####################################################################
 
NOTE:

####################### GEMDM ENVIRONMENT ############################

The very first thing one must do to work in the GEMDM environment is
to set the PATH to the proper version. This is done by issuing the 
command:
		. r.sm.dot gem [version] 
		(ex: . r.sm.dot gem 3.0.1)

There is no executable in the environment. You must create
your own. It will therefore be necessary to open an experiment
having minimally $gem/RCS_DYN as RCSPATH. A valid Makefile
can be obtained with r.make_exp. We recommend you set your working 
directory on a file system with official system backups. Since quotas
are usually limited on those file systems, we provide a script called 
"linkit" in order to link sub-directories malibIRIX64, malibSX5, output,
and process along with the main executables to a data file system
where more space is available. This script uses environment variable
"storage_model" (default: /usr/local/env/localmrb/armn/${USER}) to
determine the storage data file system.

You can create an executable with the target "gem" of the Makefile.
X-compiling is also available on pollux with ARCH=SX5.

2.0) RUNNING GEMDM:     

2.1) Interactively:

You can obtain a copy of the sample debug configuration files 
gem_settings.cfg, output.cfg and configexp.dot.cfg by running the 
scripts "gem_config dummy". This will produce a sub-directory 
"dbg1_configs" containing these 3 files. When running interactively,
a copy of files gem_settings.cfg and output.cfg must be placed locally
in the launching (working) directory.

Then, execute:

        runent          ===> to run the entry program
        runmod          ===> to run the main program

The output will be stored in directory output. A formal description
of the control parameters in gem_settings.cfg can be found in file
gem_settings.doc from directory $gem/RCS_DYN (clt_exp gem_settings.doc).

2.2) Batch mode:

File configexp.dot.cfg produced by the script gem_config is used
to control the batch mode configuration. To launch the model in batch 
mode on pollux or any one of the backends, use the scripts 
Um_launch [exp] where [exp] is the name of a subdirectory 
(like dbg1_configs) containing files gem_settings.cfg, output.cfg and 
configexp.dot.cfg. (use Um_launch -h for more details). The execution 
directory (EXECDIR) on the execution machine (mach) has the generic 
form:

        ${HOME}/gem/${mach}/${exp}

The launching scripts will require ${HOME}/gem to already
exist. The purpose of this is to force the user to provide
space for the execution of the model through a proper link
of directory ${HOME}/gem. I typically suggest that people
establish a link of the form "ln -s raid1 gem"
in the login home of the backends.

########################### END ################################
